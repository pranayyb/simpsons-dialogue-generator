{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9310620,"sourceType":"datasetVersion","datasetId":5638683}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-04T02:31:37.068402Z","iopub.execute_input":"2024-09-04T02:31:37.069340Z","iopub.status.idle":"2024-09-04T02:31:37.437069Z","shell.execute_reply.started":"2024-09-04T02:31:37.069285Z","shell.execute_reply":"2024-09-04T02:31:37.436143Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/simpsimp/input.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nbatch_size = 64 # how many independent sequences will we process in parallel?\nblock_size = 256 # what is the maximum context length for predictions?\nmax_iters = 5000\neval_interval = 500\nlearning_rate = 5e-4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 512\nn_head = 8\nn_layer = 6\ndropout = 0.1\n# ------------\n\ntorch.manual_seed(1369)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:38.358305Z","iopub.execute_input":"2024-09-04T02:31:38.358813Z","iopub.status.idle":"2024-09-04T02:31:40.022880Z","shell.execute_reply.started":"2024-09-04T02:31:38.358776Z","shell.execute_reply":"2024-09-04T02:31:40.021954Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7928073b98d0>"},"metadata":{}}]},{"cell_type":"code","source":"with open('//kaggle/input/simpsimp/input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:40.024480Z","iopub.execute_input":"2024-09-04T02:31:40.024914Z","iopub.status.idle":"2024-09-04T02:31:40.123030Z","shell.execute_reply.started":"2024-09-04T02:31:40.024879Z","shell.execute_reply":"2024-09-04T02:31:40.122068Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"text[:500]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:40.124142Z","iopub.execute_input":"2024-09-04T02:31:40.124444Z","iopub.status.idle":"2024-09-04T02:31:40.130303Z","shell.execute_reply.started":"2024-09-04T02:31:40.124407Z","shell.execute_reply":"2024-09-04T02:31:40.129404Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"Miss Hoover\\nNo, actually, it was a little of both. Sometimes when a disease is in all the magazines and all the news shows, it's only natural that you think you have it.\\n\\nLisa Simpson\\nWhere's Mr. Bergstrom?\\n\\nMiss Hoover\\nI don't know. Although I'd sure like to talk to him. He didn't touch my lesson plan. What did he teach you?\\n\\nLisa Simpson\\nThat life is worth living.\\n\\nEdna Krabappel-Flanders\\nThe polls will be open from now until the end of recess. Now, just in case any of you have decided to put \""},"metadata":{}}]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\n# create a mapping from characters to integers\nstoi = { ch:i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:40.132762Z","iopub.execute_input":"2024-09-04T02:31:40.133079Z","iopub.status.idle":"2024-09-04T02:31:40.257043Z","shell.execute_reply.started":"2024-09-04T02:31:40.133043Z","shell.execute_reply":"2024-09-04T02:31:40.256121Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Train and test splits\ndata = torch.tensor(encode(text), dtype=torch.long)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:40.258259Z","iopub.execute_input":"2024-09-04T02:31:40.259056Z","iopub.status.idle":"2024-09-04T02:31:42.274694Z","shell.execute_reply.started":"2024-09-04T02:31:40.259012Z","shell.execute_reply":"2024-09-04T02:31:42.273872Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.275770Z","iopub.execute_input":"2024-09-04T02:31:42.276109Z","iopub.status.idle":"2024-09-04T02:31:42.313373Z","shell.execute_reply.started":"2024-09-04T02:31:42.276075Z","shell.execute_reply":"2024-09-04T02:31:42.312587Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([41, 68, 78,  ..., 79, 15,  0])"},"metadata":{}}]},{"cell_type":"code","source":"n = int(0.9*len(data)) # first 90% will be train, rest val\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.314377Z","iopub.execute_input":"2024-09-04T02:31:42.314670Z","iopub.status.idle":"2024-09-04T02:31:42.319333Z","shell.execute_reply.started":"2024-09-04T02:31:42.314639Z","shell.execute_reply":"2024-09-04T02:31:42.318409Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    \n    # 1. Select the appropriate dataset (training or validation) based on the split\n    data = train_data if split == 'train' else val_data\n    \n    # 2. Generate random starting indices for the batch\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    \n    # 3. Create input sequences (x) and target sequences (y) using the random indices\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    \n    # 4. Move the data to the specified device (GPU or CPU)\n    x, y = x.to(device), y.to(device)\n    \n    return x, y\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.320651Z","iopub.execute_input":"2024-09-04T02:31:42.321276Z","iopub.status.idle":"2024-09-04T02:31:42.327742Z","shell.execute_reply.started":"2024-09-04T02:31:42.321233Z","shell.execute_reply":"2024-09-04T02:31:42.326927Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.328868Z","iopub.execute_input":"2024-09-04T02:31:42.329485Z","iopub.status.idle":"2024-09-04T02:31:42.338539Z","shell.execute_reply.started":"2024-09-04T02:31:42.329435Z","shell.execute_reply":"2024-09-04T02:31:42.337755Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    \"\"\" one head of self-attention \"\"\"\n\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # input of size (batch, time-step, channels)\n        # output of size (batch, time-step, head size)\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,hs)\n        q = self.query(x) # (B,T,hs)\n        # compute attention scores (\"affinities\")\n        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        # perform the weighted aggregation of the values\n        v = self.value(x) # (B,T,hs)\n        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.341616Z","iopub.execute_input":"2024-09-04T02:31:42.341933Z","iopub.status.idle":"2024-09-04T02:31:42.351242Z","shell.execute_reply.started":"2024-09-04T02:31:42.341901Z","shell.execute_reply":"2024-09-04T02:31:42.350419Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    \"\"\" multiple heads of self-attention in parallel \"\"\"\n\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(head_size * num_heads, n_embd)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.352392Z","iopub.execute_input":"2024-09-04T02:31:42.353004Z","iopub.status.idle":"2024-09-04T02:31:42.361953Z","shell.execute_reply.started":"2024-09-04T02:31:42.352958Z","shell.execute_reply":"2024-09-04T02:31:42.361125Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class FeedFoward(nn.Module):\n    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.363037Z","iopub.execute_input":"2024-09-04T02:31:42.363856Z","iopub.status.idle":"2024-09-04T02:31:42.370480Z","shell.execute_reply.started":"2024-09-04T02:31:42.363819Z","shell.execute_reply":"2024-09-04T02:31:42.369632Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        # n_embd: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedFoward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.371568Z","iopub.execute_input":"2024-09-04T02:31:42.371856Z","iopub.status.idle":"2024-09-04T02:31:42.382026Z","shell.execute_reply.started":"2024-09-04T02:31:42.371826Z","shell.execute_reply":"2024-09-04T02:31:42.381274Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class GPTLanguageModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n        # better init, not covered in the original GPT video, but important, will cover in followup video\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        # idx and targets are both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last block_size tokens\n            idx_cond = idx[:, -block_size:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.383021Z","iopub.execute_input":"2024-09-04T02:31:42.383321Z","iopub.status.idle":"2024-09-04T02:31:42.397194Z","shell.execute_reply.started":"2024-09-04T02:31:42.383288Z","shell.execute_reply":"2024-09-04T02:31:42.396191Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = GPTLanguageModel()\nm = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.398381Z","iopub.execute_input":"2024-09-04T02:31:42.398712Z","iopub.status.idle":"2024-09-04T02:31:42.982371Z","shell.execute_reply.started":"2024-09-04T02:31:42.398674Z","shell.execute_reply":"2024-09-04T02:31:42.981384Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.983689Z","iopub.execute_input":"2024-09-04T02:31:42.984089Z","iopub.status.idle":"2024-09-04T02:31:42.991154Z","shell.execute_reply.started":"2024-09-04T02:31:42.984046Z","shell.execute_reply":"2024-09-04T02:31:42.990282Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"19.174534 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:42.992201Z","iopub.execute_input":"2024-09-04T02:31:42.992507Z","iopub.status.idle":"2024-09-04T02:31:43.887030Z","shell.execute_reply.started":"2024-09-04T02:31:42.992469Z","shell.execute_reply":"2024-09-04T02:31:43.886046Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for iter in range(max_iters):\n\n    # every once in a while evaluate the loss on train and val sets\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    # sample a batch of data\n    xb, yb = get_batch('train')\n\n    # evaluate the loss\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T02:31:43.888197Z","iopub.execute_input":"2024-09-04T02:31:43.888628Z","iopub.status.idle":"2024-09-04T03:51:02.956659Z","shell.execute_reply.started":"2024-09-04T02:31:43.888580Z","shell.execute_reply":"2024-09-04T03:51:02.955769Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"step 0: train loss 5.1624, val loss 5.1569\nstep 500: train loss 1.4880, val loss 1.4985\nstep 1000: train loss 1.2461, val loss 1.2706\nstep 1500: train loss 1.1535, val loss 1.1873\nstep 2000: train loss 1.0952, val loss 1.1305\nstep 2500: train loss 1.0621, val loss 1.1008\nstep 3000: train loss 1.0371, val loss 1.0771\nstep 3500: train loss 1.0164, val loss 1.0663\nstep 4000: train loss 1.0000, val loss 1.0577\nstep 4500: train loss 0.9859, val loss 1.0545\nstep 4999: train loss 0.9733, val loss 1.0426\n","output_type":"stream"}]},{"cell_type":"code","source":"# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))\n#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-09-04T03:51:02.958156Z","iopub.execute_input":"2024-09-04T03:51:02.958575Z","iopub.status.idle":"2024-09-04T03:55:05.578937Z","shell.execute_reply.started":"2024-09-04T03:51:02.958539Z","shell.execute_reply":"2024-09-04T03:55:05.578009Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\nAnother house at Fruit as undected a yange, and nerds made a big football place.\n\nWaylon Smithers\nYell, sir.\n\nC. Montgomery Burns\nThere was hard...\n\nHomer Simpson\nHe's boring a dead.\n\nC. Montgomery Burns\nHere, his full roll... Want a state in your kname?\n\nDick Commandant\nLet's see if you know why beat.\n\nWaylon Smithers\nIf I poke crapped till Taunt Sergeant, you're a ghost, right?\n\nMoe Szyslak\nOh, foast.\n\nAvatar Bart\nBack.\n\nAvatar Bart\nI question time appearation at night one of them lamp. But as we doing all them our name.\n\nSeymour Skinner\nFor what?! Bart, what could be?\n\nEdna Krabappel-Flanders\nSee they, what's they afraid some standin'?\n\nBart Simpson\nI wouldent.\n\nBart Simpson\nHad this guard to be no catchbackstoma.\n\nLisa Simpson\nStop by your old morning clock. This is a replaining minute. You can represe when you get people to defeat a tree?\n\nHomer Simpson\nStop, don't blind me just like thinking. I wanna be death... sister... but I do whisk that watch.\n\nMarge Simpson\nFlanders, kids never thinks of \"Marge foam\"! \"Children.\"\n\nAdults\nThis main hits are watching your firsts!\n\nLisa Simpson\nOh I have my first codes, but they've poked to hurt. / I'm nutting it...\n\nLisa Simpson\nIt's never married to appear -- one more case has a movie, / amenda Privanium.\n\nChief Wiggum\nHey, in a portune, big corn.\n\nBart Simpson\nThank you, Sergeant Dolph.\n\nMarge Simpson\nHey, I still wonder what's for you: ship shippies.\n\nMarge Simpson\nBoys don't worry. I'm only gonna have a peace tighter of work, but I'm one peace!\n\nHomer Simpson\nI want to be whistle.\n\nMarge Simpson\nHe said it was in the closet. It goes. Cons?ect Oliven time is the bus. Caricaca, mins deate, conset... and the time is at the peace weapont.\n\nGary Chalmers\nWell, hey, I won. Been Bob, deated.\n\nBart Simpson\nBob, I please stopped resnibiliting ourselves.\n\nBart Simpson\nUm... Guessing me?\n\nSeymour Skinner\nWipped in your head.\n\nNelson Muntz\nYou're bringing it!\n\nSeymour Skinner\nWhat?\n\nLisa Simpson\nMom? Describing your needs like this.\n\nNelson Muntz\nThis is a video pocket!\n\nMartin Prince\nIs it?\n\nMartin Prince\nIs it a peace.\n\nMartin Prince\nAnd... the moral Queart: The Mabru bra-loan pretty...\n\nEdna Krabappel-Flanders\nBehold... We go...\n\nMarch\nIt decidentites that the mabrea way to chake our clientest car.\n\nFemale Grince\nMy Family.\n\nMarchist\nOh, there it is, I don't have right to be a nuclear radio. I got my turn.\n\nBet Homer\nI got an identific in your showl.\n\nBet Harden\nAnd Edish, \"yours' inside: I dreamed, the school was just absolved by the Savagr Bus Debbug.\"\n\nBet Hardbug\nBut try a watch. I thought we are still at everything that's cute.\n\nBart Simpson\nGuten cleaners?\n\nBet Harvey Hardbug\nNo, no, I I have so much bet to win siptive. I made a bunch monkey you holRisk it.\n\nExcusive-eigner\nNow, uh, but I've just gotta ask him.\n\nSeymour Skinner\nThat horse character you.\n\nSeymour Skinner\nA silgeril in eleven. Are those up to charge, pass one's charging as changing up a civic dad.\n\nMilhouse Van Houten\nMy grampa was loved!\n\nLisa Simpson\nPure like Marge's coming like you'em, Maggie.\n\nBoy's Vatrollike\nWell please, meet minue revenge. Someone remembered you'd be their mailed!\n\nLisa Simpson\nYee've been tried from showting? In a crime, I'll buy a show right.\n\nBoys Instructor\nNo abuset. My favor exits is a peace of friyte mug -- the Pricess Gay brisy was worth elbump! Go get the Amusemental walkin'.\n\nBoys Interstitutional Wine\nThat's not time. I think I'm charging to get lest, Stu are just.\n\nMilhouse Van Houten\nHeh, heh.\n\nStudent Kid\nThen it crisis crisis, dobbing to win bacilific bones and wind beging, and after student marlignal dead in front of our drives. Edna. He got picked up?\n\nGrampa Simpson\nHe cut...\n\nStepherbiter #2\nHe's a lot.\n\nHomer Simpson\nHey, can you imaturn your heart?\n\nGravepad-lyed-lo-ter #1\nBudget right.\n\nMoe Szyslak\nWhat is pink yoff?\n\nMoe Szyslak\nCall this \"ingent,\" everybody ofly with this incrediblic carge afternoon.\n\nMoe Szyslak\nIt does go or artirement!\n\nMoe Szyslak\nHow do you be married?\n\nGravepador\nYou shared your dinger back to me. Shave your futher whack.\n\nMoe Szyslak\nEasy whack?\n\nLenny Leonard\nEasy.\n\nBart Simpson\nGet out!\n\nDOLPH\nAll right! I'll help you!\n\nDOLPH\nI'm not the loose thank\"Land it.\n\nDOLPH\nLet's do this.\n\nDOLPH\nThis, drunk up, Homer!\n\nARTIE\nWhat are you doing here? Or say \"Or where the?\"\n\nBart Simpson\nMaybe someone needs, we were going to drunk...\n\nBart Simpson\nI won't even appreciate your \"Bourns\" -- are from my such champadreness state...\n\nBart Simpson\nYou know, Milhouse Van donut?\n\nBart Simpson\nThat's for the week. It smells, my oon.\n\nBart Simpson\nLook at this.\n\nLisa Simpson\nIs it disaptiousely? No, then I urder!\n\nBart Simpson\nOatmeal!\n\nDr. Julius Hibbert\nIt says may make humiliating.\n\nVarious Kid\nIsn't this fitness?\n\nBart Simpson\nNo.\n\nVarious Hibbert #1\nMuust be on information... Yidium-licide. Leicing their sexual life.\n\nBart Simpson\nThere's no one walking a film walking right now.\n\nBart Simpson\nBet, I think of I was too bringing about around, but. Then I can't. And tonight everyone wear celebrities?\n\nBart Simpson\nEw.\n\nGrampa Simpson\nI agree about Hard School's hearing question-in-ly. Thank you for his artically, um...\n\nBart Simpson\nIt can't be a party!\n\nNelson Muntz\nWhile other partners were dinner. I don't, but you'll make disn't dissect your case...\n\nBart Simpson\n...seventies contentent. They start on murder!\n\nBart Simpson\nHurley.\n\nBart Simpson\nAnd will you telll them what you lips that are playing sauce as a wheel?\n\nNun\nNice work, Sir.\n\nBart Simpson\nIntraguirely Foctory horrorsc it: It's a hungry.\n\nFortune's Foreman\nIt's acquiding that your machine sauce.\n\nBart Simpson\nMuss sounds like here I couldn't like. She made us all that hoste.\n\nHomer Simpson\nHow war sick?\n\nComic Book Guy\nSeÃƒÂ¤noma long Maisu says that therx? Sickle that kid over agic of compless their sauce.\n\nComic Book Guy\nTonil with cement past theirs.\n\nMarge Simpson\nNo imaginar.\n\nHomer Simpson\nHmmm... Isn't that sick or I'm afraid it?!\n\nDriver\nI still can't believe I reverse wants a bigger than better!\n\nMarge Simpson\nA lot version. But he proof you ever call music tarters, Barthol...\n\nMilhouse Van Houten\nIf it's a dog like Bartholomew just like you want to play to the wife.\n\nKearney Zzyzwicz\nOh, I wanted a guy to go first... Herry there.. Hm, eh? Here is he dared her comin' from you... Aha, herry the Huggers. Th-Y-Y? A Two and you wait down for all day...\n\nMarge Simpson\nHomie... Hey, there's my naving chops.\n\nHomer Simpson\nUm, this question has a antiquestion.\n\nMarge Simpson\nIt is, musical the store. All the terrible cements meanetic and TV? The celebrity store machine to support airplane!\n\nHomer Simpson\nStupid free tickets! The celebration all you carame!\n\nC. Montgomery Burns\nIn the oven wasnut in this plamt dirty-five kilton. If they lose this planned for their secrets once and racer House Ghrimarium! The article in his concert air will know it'll incare be.\n\nHomer Simpson\nAnd sometime you... build it up! Building me from their daddy stappy.\n\nMarge Simpson\nSometimes they're gonna die!\n\nHomer Simpson\nWell... we'd be a movie.\n\nMarge Simpson\nHey, Kids remember that!\n\nSeymour Skinner\nHi-pot-off.\n\nNelson Muntz\nHi-pot-diddily-fill-lacation?!\n\nMartin Prince\nA room was giving me.\n\nRamona\nAlphy for you. Mr. Simpson.\n\nActivice\nMr-ngmither makes functures it rules and body beats. His activing guns.\n\nBart Simpson\nCome on, Dad.\n\nLenny Leonard\nHey Leonard.\n\nCarl Carlson\nOh, the God told me more insana. Ha, pull your monkey.\n\nC. Moone\nOh, show ships all you destroy something?\n\nMeasomner #1\nWell, that would be on the TV that guard... the year... the popcorn ships...\n\nMilhouse Van Houten\nBut I've tell you what the year you said... what? Think what the...\n\nNelson Muntz\nYou grabbly maybe it? I quit it!\n\nBart Simpson\nEverything I mist! That's what you've done!\n\nEleves\nEw. That's beonk, too.\n\nElevely Overst\nOh, oh, can't I just... Homer, you're tired of Hellhoigh...\n\nGrampa Simpson\nNo, don't like the pink...\n\nLisa Simpson\nBut we have confused hert.\n\nHomer Simpson\nRead corport?\n\nLisa Simpson\nCorporation? Damn, I cannot admit, you just waitin'.\n\nGrampa Simpson\nI see it's ready to be by some Write Daddy.\n\nBoys\nHuh?\n\nHenry\nI'd like to say this. I'm just as well-estate.\n\nHomer Simpson\nYeah. I work in time to the car...\n\nBobo\nI deserve the other human I made any pencil wear nothing. He can't work. I mean you to my unspokenda trick. Anyway, I'll apply you with Monk Simpson, I could have made off a slate downing these school boy I've been negotiating only now.\n\nBart Simpson\nBut I'll live off my order too. Wisculation, isn't it?\n\nHomer Simpson\nI said a Monk Simpson.\n\nBart Simpson\nBet it says \"lousy stuff space-jace\"...\n\nMarge Simpson\nI sawdicked my sister cousins.\n\nDissoversions\nAlright, please?\n\nC. Montgomery Burns\nYou gotta get that. It sets from it aBuseppearing.\n\nBart Simpson\nAs anyone else end of soil?\n\nDickeditor\nNo, it shows were just a pantsas family. They have a baseball gate.\n\nBart Simpson\nHey! Take that grab mujat!\n\nBart Simpson\nHey Homer, at this last bear, haring everynthing?\n\nBart Simpson\nWe gotta find your cheering curch.\n\nBart Simpson\nI thought you were never gonna find bet grave the point.\n\nBart Simpson\nHey, there's go to see your apple... why doesn't anyone hitting the tap without both?!\n\nBart Simpson\nLemme stop! Tap bitting me! Tap! At these bars?!\n\nBart Simpson\nAm I, sweetie, you're all being laucrets?\n\nBart Simpson\nBut why did you ask Franciers people to your per stillic prankster than flash in?\n\nLisa Simpson\nSort aren't... lemmers... an out-grossing words are spelling weeks in there! Next to me... depare cooks, eh?!\n\nBart Simpson\nHow's gonna late?\n\nBart Simpson\nArders' engagement at the Tipstern of Springfield?\n\nBart Simpson\nHey you, don't worry.\n\nBart Simpson\nI don't want to you build. Nothing's gonna rab is up.\n\nBart Simpson\nWhere are we going?\n\nBart Simpson\nThe barrine store!\n\nMarge Simpson\nJust the bests I.QUIT I can't leave.\n\nBart Simpson\nThese barrians lines are knocking.\n\nTeddy\nR\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'simpsons-dialogue-generator.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T04:22:35.382449Z","iopub.execute_input":"2024-09-04T04:22:35.383175Z","iopub.status.idle":"2024-09-04T04:22:35.537580Z","shell.execute_reply.started":"2024-09-04T04:22:35.383134Z","shell.execute_reply":"2024-09-04T04:22:35.536816Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'simpsons-dialogue-generator.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T04:22:48.735185Z","iopub.execute_input":"2024-09-04T04:22:48.735551Z","iopub.status.idle":"2024-09-04T04:22:48.742074Z","shell.execute_reply.started":"2024-09-04T04:22:48.735518Z","shell.execute_reply":"2024-09-04T04:22:48.741185Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/simpsons-dialogue-generator.pth","text/html":"<a href='simpsons-dialogue-generator.pth' target='_blank'>simpsons-dialogue-generator.pth</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"## this is used to load model into the app file\n\n# @st.cache_resource\n# def load_model():\n#     model = GPTLanguageModel()\n#     model.load_state_dict(torch.load('simpsons-dialogue-generator.pth', map_location=torch.device('cpu')))\n#     model.eval()\n#     return model\n\n# model = load_model()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T04:23:40.322264Z","iopub.execute_input":"2024-09-04T04:23:40.322869Z","iopub.status.idle":"2024-09-04T04:23:40.326830Z","shell.execute_reply.started":"2024-09-04T04:23:40.322827Z","shell.execute_reply":"2024-09-04T04:23:40.325891Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# End!","metadata":{}}]}